{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import open_clip\n",
    "from open_clip import tokenizer\n",
    "from deep_translator import GoogleTranslator\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "high_model, _, high_preprocess = open_clip.create_model_and_transforms('ViT-H-14', pretrained='laion2b_s32b_b79k')\n",
    "high_model.eval()  \n",
    "high_model = high_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_model, _, low_preprocess = open_clip.create_model_and_transforms('ViT-B-32', pretrained='laion2b_s34b_b79k')\n",
    "low_model.eval()\n",
    "low_model = low_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'darkA': 'There is dark green grass growing, but no white, blue or black objects have fallen.', 'darkB': 'There is a lot of thin grass growing, but no white, blue or black objects have fallen.', 'Light A': 'There is light green grass growing, but no white, blue or black objects have fallen.', 'Light B': 'There is a lot of thin grass growing, but no white, blue or black objects have fallen.', 'whiteA': 'The beach is white with piled-up sand and no grass growing on it, and there are no white, blue or black objects on it.', 'White B': 'There is sand piled up on the white beach and a little grass growing on it, but there are no white, blue or black objects on the beach.', 'Object A': 'There is dark green grass growing and at least one of the following objects is lying on the ground: white, blue, or black.', 'Object B': 'There is a lot of thin grass growing, and at least one of the following objects is lying around: white, blue, or black.', 'Object C': 'A beach with white sand, light green grass and at least one white, blue, or black object lying on it.', 'Object D': 'A white sandy beach with thin grass growing on it and at least one white, blue, or black object lying on it.', 'Object E': 'The white beach is covered with sand and no grass, but there is at least one white, blue, or black object lying on it.', 'Object F': 'A white beach with piled-up sand and a small amount of grass growing on it, and at least one white, blue, or black object lying on the ground.'}\n"
     ]
    }
   ],
   "source": [
    "# DeeplTranslatorのインスタンスを作成\n",
    "translator = GoogleTranslator(source='ja', target='en')\n",
    "\n",
    "# 辞書の定義\n",
    "descriptions = {\n",
    "    \"darkA\": \"緑色が濃い草が生えているが、白色の物体や青色の物体、黒色の物体は落ちていない\",\n",
    "    \"darkB\": \"細い草がたくさん生えているが、白色の物体や青色の物体、黒色の物体は落ちていない\",\n",
    "    \"lightA\": \"緑色が薄い草が生えているが、白色の物体や青色の物体、黒色の物体は落ちていない\",\n",
    "    \"lightB\": \"細い草がたくさん生えているが、白色の物体や青色の物体、黒色の物体は落ちていない\",\n",
    "    \"whiteA\":\"灰色の砂浜の上に砂が積もっていて草も生えておらず、白色の物体や青色の物体、黒色の物体は落ちていない\",\n",
    "    \"whiteB\":\"灰色の砂浜の上に砂が積もっていて少しだけ草が生えているが、白色の物体や青色の物体、黒色の物体は落ちていない\",\n",
    "    \"物体A\":\"緑色が濃い草が生えている上に、白色の物体や青色の物体、黒色の物体の少なくとも１つが落ちている\",\n",
    "    \"物体B\":\"細い草がたくさん生えている上に、白色の物体や青色の物体、黒色の物体の少なくとも１つが落ちている\",\n",
    "    \"物体C\":\"灰色の砂浜の上に緑色が薄い草が生えている上に、白色の物体や青色の物体、黒色の物体の少なくとも１つが落ちている\",\n",
    "    \"物体D\":\"灰色の砂浜の上に細い草が生えている上に、白色の物体や青色の物体、黒色の物体の少なくとも１つが落ちている\",\n",
    "    \"物体E\":\"灰色の砂浜の上に砂が積もっていて草も生えていないが、白色の物体や青色の物体、黒色の物体の少なくとも１つが落ちている\",\n",
    "    \"物体F\":\"灰色の砂浜の上に砂が積もっていて少しだけ草が生えている上に、白色の物体や青色の物体、黒色の物体の少なくとも１つが落ちている\",\n",
    "    \"物体G\":\"灰色の砂浜の上に青色の物体、草ではない緑色の物体、黒色の物体の少なくとも１つが落ちている\"\n",
    "}\n",
    "\n",
    "descriptions = {translator.translate(key): translator.translate(value) for key, value in descriptions.items()}\n",
    "\n",
    "# 翻訳した辞書を表示\n",
    "print(descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 元のフォルダパス\n",
    "source_base_path = \"imgs/update_img\"\n",
    "# コピー先のフォルダパス\n",
    "destination_path = \"imgs/clip_test\"\n",
    "\n",
    "# コピー先のフォルダを作成\n",
    "os.makedirs(destination_path, exist_ok=True)\n",
    "\n",
    "# サブフォルダを取得\n",
    "subfolders = [f for f in os.listdir(source_base_path) if os.path.isdir(os.path.join(source_base_path, f))]\n",
    "\n",
    "# 各サブフォルダからランダムにn枚ずつ画像をコピー\n",
    "for subfolder in subfolders:\n",
    "    subfolder_path = os.path.join(source_base_path, subfolder)\n",
    "    images = [f for f in os.listdir(subfolder_path) if os.path.isfile(os.path.join(subfolder_path, f))]\n",
    "    \n",
    "    # ランダムに2枚選択\n",
    "    selected_images = random.sample(images, 15)\n",
    "    \n",
    "    for image in selected_images:\n",
    "        source_file = os.path.join(subfolder_path, image)\n",
    "        destination_file = os.path.join(destination_path, f\"{subfolder}_{image}\")\n",
    "        \n",
    "        # 画像をコピー\n",
    "        shutil.copy(source_file, destination_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "予測結果の保存が完了しました。\n"
     ]
    }
   ],
   "source": [
    "clip_test_path = destination_path\n",
    "result_path = \"imgs/clip_test_result\"\n",
    "# 結果フォルダを作成\n",
    "os.makedirs(result_path, exist_ok=True)\n",
    "\n",
    "# 画像の予測とプロット\n",
    "for image_name in os.listdir(clip_test_path):\n",
    "    image_path = os.path.join(clip_test_path, image_name)\n",
    "    if os.path.isfile(image_path):\n",
    "        # 画像の読み込みと前処理\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        high_input = high_preprocess(image).unsqueeze(0).to(device)\n",
    "        low_input = low_preprocess(image).unsqueeze(0).to(device)\n",
    "\n",
    "        # テキストの前処理\n",
    "        texts = list(descriptions.values())\n",
    "        text_tokens = open_clip.tokenize(texts).to(device)\n",
    "\n",
    "        # 予測\n",
    "        with torch.no_grad():\n",
    "            high_img_embedding = high_model.encode_image(high_input)\n",
    "            high_text_embedding = high_model.encode_text(text_tokens)\n",
    "            low_img_embedding = low_model.encode_image(low_input)\n",
    "            low_text_embedding = low_model.encode_text(text_tokens)\n",
    "\n",
    "        # コサイン類似度を計算\n",
    "        high_probs = (100 * high_img_embedding @ high_text_embedding.T).softmax(dim=-1)\n",
    "        low_probs = (100 * low_img_embedding @ low_text_embedding.T).softmax(dim=-1)\n",
    "\n",
    "        # 結果のプロット\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "        \n",
    "        # 画像の表示\n",
    "        ax[0].imshow(image)\n",
    "        ax[0].axis('off')\n",
    "        ax[0].set_title(f\"Image: {image_name}\")\n",
    "\n",
    "        # 予測結果の棒グラフ\n",
    "        labels = list(descriptions.keys())\n",
    "        high_values = high_probs.squeeze().detach().cpu().numpy()\n",
    "        low_values = low_probs.squeeze().detach().cpu().numpy()\n",
    "        x = np.arange(len(labels))\n",
    "        width = 0.35\n",
    "        ax[1].bar(x - width/2, high_values, width, label='High Model', color='blue', alpha=0.5)\n",
    "        ax[1].bar(x + width/2, low_values, width, label='Low Model', color='green', alpha=0.5)\n",
    "        ax[1].set_title(\"Model Predictions\")\n",
    "        ax[1].set_ylabel(\"Probability (%)\")\n",
    "        ax[1].legend()\n",
    "        ax[1].set_xticks(x)\n",
    "        ax[1].set_xticklabels(labels, rotation=45, ha='right')\n",
    "\n",
    "        # 結果の保存\n",
    "        result_image_path = os.path.join(result_path, f\"{image_name}_result.png\")\n",
    "        plt.savefig(result_image_path)\n",
    "        plt.close(fig)\n",
    "\n",
    "print(\"予測結果の保存が完了しました。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "画像の分類と保存が完了しました。\n"
     ]
    }
   ],
   "source": [
    "# 画像フォルダのパス\n",
    "source_base_path = \"imgs/update_img\"\n",
    "result_base_path = \"imgs/clip_result\"\n",
    "\n",
    "# 結果フォルダを作成\n",
    "os.makedirs(result_base_path, exist_ok=True)\n",
    "high_result_path = os.path.join(result_base_path, \"high\")\n",
    "low_result_path = os.path.join(result_base_path, \"low\")\n",
    "os.makedirs(high_result_path, exist_ok=True)\n",
    "os.makedirs(low_result_path, exist_ok=True)\n",
    "\n",
    "# サブフォルダを取得\n",
    "subfolders = [f for f in os.listdir(source_base_path) if os.path.isdir(os.path.join(source_base_path, f))]\n",
    "\n",
    "# 画像の予測と分類\n",
    "for subfolder in subfolders:\n",
    "    subfolder_path = os.path.join(source_base_path, subfolder)\n",
    "    high_yes_path = os.path.join(high_result_path, subfolder, \"yes\")\n",
    "    high_no_path = os.path.join(high_result_path, subfolder, \"no\")\n",
    "    low_yes_path = os.path.join(low_result_path, subfolder, \"yes\")\n",
    "    low_no_path = os.path.join(low_result_path, subfolder, \"no\")\n",
    "    os.makedirs(high_yes_path, exist_ok=True)\n",
    "    os.makedirs(high_no_path, exist_ok=True)\n",
    "    os.makedirs(low_yes_path, exist_ok=True)\n",
    "    os.makedirs(low_no_path, exist_ok=True)\n",
    "    \n",
    "    for image_name in os.listdir(subfolder_path):\n",
    "        image_path = os.path.join(subfolder_path, image_name)\n",
    "        if os.path.isfile(image_path):\n",
    "            # 画像の読み込みと前処理\n",
    "            image = Image.open(image_path).convert(\"RGB\")\n",
    "            high_input = high_preprocess(image).unsqueeze(0).to(device)\n",
    "            low_input = low_preprocess(image).unsqueeze(0).to(device)\n",
    "\n",
    "            # テキストの前処理\n",
    "            texts = list(descriptions.values())\n",
    "            text_tokens = open_clip.tokenize(texts).to(device)\n",
    "\n",
    "            # 予測\n",
    "            with torch.no_grad():\n",
    "                high_img_embedding = high_model.encode_image(high_input)\n",
    "                high_text_embedding = high_model.encode_text(text_tokens)\n",
    "                low_img_embedding = low_model.encode_image(low_input)\n",
    "                low_text_embedding = low_model.encode_text(text_tokens)\n",
    "\n",
    "            # コサイン類似度を計算\n",
    "            high_probs = (100 * high_img_embedding @ high_text_embedding.T).softmax(dim=-1)\n",
    "            low_probs = (100 * low_img_embedding @ low_text_embedding.T).softmax(dim=-1)\n",
    "\n",
    "            # 物体があるかないかの判断\n",
    "            high_max_prob, high_max_index = torch.max(high_probs, dim=-1)\n",
    "            low_max_prob, low_max_index = torch.max(low_probs, dim=-1)\n",
    "            high_label = list(descriptions.keys())[high_max_index]\n",
    "            low_label = list(descriptions.keys())[low_max_index]\n",
    "\n",
    "            # high_modelの分類\n",
    "            if high_label.startswith(\"Object\"):\n",
    "                shutil.copy(image_path, os.path.join(high_yes_path, image_name))\n",
    "            else:\n",
    "                shutil.copy(image_path, os.path.join(high_no_path, image_name))\n",
    "\n",
    "            # low_modelの分類\n",
    "            if low_label.startswith(\"Object\"):\n",
    "                shutil.copy(image_path, os.path.join(low_yes_path, image_name))\n",
    "            else:\n",
    "                shutil.copy(image_path, os.path.join(low_no_path, image_name))\n",
    "\n",
    "print(\"画像の分類と保存が完了しました。\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
